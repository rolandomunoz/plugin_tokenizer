# Tokenizer

This is a Praat plug-in which helps in linguistic segmentation of textual data. It can split a text into a subset of segmented units such as words, syllables, or segments. The plug-in assumes that your transcriptions are stored in [TextGrid](http://www.fon.hum.uva.nl/praat/manual/TextGrid.html) files, so it takes them as the starting point for the creation of new optional tiers which contain the segmented information. 

The Figure from below is an example how this plug-in works. The three topmost tiers (segment, syllable, word)  were derived from the fourth one (text). We can also observe that the segmented units are delimited by intervals.
![Imgur](http://i.imgur.com/2SN7S6Il.png)

## More information
You can visit the [Wiki project](https://github.com/rolandomunoz/plugin_tokenizer/wiki), so you can get more documentation.

The [Getting started](https://github.com/rolandomunoz/plugin_tokenizer/wiki/Getting-Started) section will walk you through the basics.

In [How it works](https://github.com/rolandomunoz/plugin_tokenizer/wiki/How-it-works%3F) you will get an idea about the internal process that are taken. (under construction)
